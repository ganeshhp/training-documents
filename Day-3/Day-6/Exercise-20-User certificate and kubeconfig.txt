## let's understand the Public Key Infrastructure (PKI) setup on control plane node.

$ ls -l /etc/kubernetes/pki

## note the ca.crt and ca.key files.

## let's read the ca.crt to view certificate information
$ openssl x509 -in /etc/kubernetes/pki/ca.crt -text -noout | more

### now let's look at the kubeconfig file in /etc/kubernetes

$ sudo more /etc/kubernetes/scheduler.conf

$ sudo kubectl config view --kubeconfig=/etc/kubernetes/scheduler.conf

$ kubectl get configMap --namespace kube-system kube-proxy -o yaml

------------------------

## creating certificate with 'certificate signing request' api

$ openssl genrsa -out newuser.key 2048
## generate a CSR cert.

$ openssl req -new -key newuser.key -out newuser.csr -subj "/CN=newuser"

## new the CertificateSigningRequest needs to be base64 encoded

$ cat newuser.csr | base64 | tr -d "\n" > newuser.base64.csr


### now let's create a file using heredoc and CertificateSigningRequest object.

cat <<EOF | kubectl apply -f -
apiVersion: certificates.k8s.io/v1
kind: CertificateSigningRequest
metadata:
  name: newuser
spec:
  groups:
  - system:authenticated
  request: $(cat newuser.base64.csr)
  signerName: kubernetes.io/kube-apiserver-client
  usages:
  - client auth
EOF

-------------

$ kubectl get certificatesigningrequests

## approve the certificate

$ kubectl certificate approve newuser

### validate status of request.

$ kubectl get certificatesigningrequests

## retrieve the certificate from the CSR object, it's base64 encoded

$ kubectl get certificatesigningrequests newuser \
  -o jsonpath='{ .status.certificate }' | base64 --decode > newuser.crt


$ openssl x509 -in newuser.crt -text -noout | head -n 15

### note the certificate validity.

#### Understanding Kubeconfig

$ kubectl config view

$ kubectl config view --raw
$ more ~/.kube/config

### now that we have got the config file and the user certificates created we can give the new user certain rights to access the cluster info.

$ kubectl create ClusterRoleBinding newuserclusterrolebinding \
 --clusterrole=view --user=newuser

## creating Kubeconfig file manually.
### first define the cluster
$ kubectl config set-cluster kubernetes-cluster \
  --server=https://10.142.0.8:6443 \
  --certificate-authority=/etc/kubernetes/pki/ca.crt \
  --embed-certs=true \
  --kubeconfig=newuser.conf

### so, a new kubeconfig file is created in the current working directory.

$ ls newuser.conf

## let's confirm the cluster is created.

$ kubectl config view --kubeconfig=newuser.conf

### define a credential for the newuser in the kubeconfig file

$ kubectl config set-credentials newuser \
  --client-key=newuser.key \
  --client-certificate=newuser.crt \
  --embed-certs=true \
  --kubeconfig=newuser.conf


$ kubectl config view --kubeconfig=newuser.conf

### define context, context name, cluster name and username

$ kubectl config set-context newuser@kubernetes-cluster \
  --cluster=kubernetes-cluster \
  --user=newuser \
  --kubeconfig=newuser.conf

## let's view the new config file with all details for the cluster, context and user.

$ kubectl config view --kubeconfig=newuser.conf

### now Set the current-context

$ kubectl config use-context \
  newuser@kubernetes-cluster --kubeconfig=newuser.conf


### Now let's create some workload for the new user

$ kubectl create deployment nginx --image=nginx -v 6

## test the connection for the newuser to the cluster.

$ kubectl get pods --kubeconfig=newuser.conf -v 6

### note the logs where it is mentioned that the config is loaded from file newuser.conf. currently the user is allowed to view the cluster object but not any modification to the cluster.

## we will also set the default kubeconfig file that we will use for every kubectl query.

$ export KUBCONFIG=newuser.conf

$ kubectl get pods -v 6

## note that now without stating the kubeconfig file  reference we are able to connect and query the cluster.


--------------

## now we are going to use a new Linux user, newuser and then create the new kubeconfig file for that user.

$ sudo useradd -m newuser

$ sudo mkdir -p /home/newuser/.kube
$ sudo cp -i newuser.conf /home/newuser/.kube/config
$ sudo chown -R newuser:newuser /home/newuser/.kube

## let's switch to the newuser using sudo su command,

$ sudo su newuser

$ cd ~

$ kubectl config view

$ kubectl get pods -v 6

## note the kubeconfig file reference in the command execution.

$ exit

## reset all the changes we had done for the newuser.

$ kubectl delete deployment nginx.

$ kubectl delete clusterrolebinding newuserclusterrolebinding



 


